{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "improve_accuracy_and_upload.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5HEkgJW62Zhq"
      },
      "source": [
        "Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "ZvnzHC7lmzWB",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mxPxpHKHMAkl"
      },
      "source": [
        "# Step **12**: Deploy a second model to Firebase ML\n",
        "\n",
        "This is the notebook for step **12** of the codelab [**Add Firebase to your TensorFlow Lite-powered app**](https://codelabs.developers.google.com/codelabs/digit-classifier-tflite/).\n",
        "\n",
        "In this notebook, we will train an improved version of the handwritten digit classification model using data augmentation. Then we will upload the model to Firebase using the [Firebase ML Model Management API](https://firebase.google.com/docs/ml-kit/manage-hosted-models).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/lite/codelabs/digit_classifier/ml/step7_improve_accuracy.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/lite/codelabs/digit_classifier/ml/step7_improve_accuracy.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p8bO0hupMdZM"
      },
      "source": [
        "## Train an improved TensorFlow Lite model\n",
        "\n",
        "Let's start by training the improved model. \n",
        "\n",
        "We will not go into details about the model training here but if you are interested to learn more about why we apply data augmentation to this model and other details, check out this [notebook](https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/lite/codelabs/digit_classifier/ml/step7_improve_accuracy.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nImr6z7TMBJQ",
        "colab": {}
      },
      "source": [
        "# Import dependencies\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Import MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Add a color dimension to the images in \"train\" and \"validate\" dataset to\n",
        "# leverage Keras's data augmentation utilities later.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "\n",
        "# Define data augmentation configs\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "  rotation_range=30,\n",
        "  width_shift_range=0.25,\n",
        "  height_shift_range=0.25,\n",
        "  shear_range=0.25,\n",
        "  zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Generate augmented data from MNIST dataset\n",
        "train_generator = datagen.flow(train_images, train_labels)\n",
        "test_generator = datagen.flow(test_images, test_labels)\n",
        "\n",
        "# Define and train the Keras model.\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Dropout(0.25),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_generator, epochs=5, validation_data=test_generator)\n",
        "\n",
        "# Convert Keras model to TF Lite format and quantize.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "with open('mnist_v2.tflite', \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpTQf5gHJz78",
        "colab_type": "text"
      },
      "source": [
        "## Publish model to Firebase ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "Step 1. Upload the private key (json file) for your service account and Initialize Firebase Admin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jALZvgQ2zwfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import firebase_admin\n",
        "from firebase_admin import ml\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/content/' + fn\n",
        "  projectID = fn.rsplit(\"-firebase\")[0]\n",
        "  firebase_admin.initialize_app(\n",
        "      options={'projectId': projectID, \n",
        "               'storageBucket': projectID + '.appspot.com' })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULfDUSYjiNqk",
        "colab_type": "text"
      },
      "source": [
        "Step 2.  Upload the model file to Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fRsDDJyiWFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This uploads it to your bucket as mmnist_v2.tflite\n",
        "source = ml.TFLiteGCSModelSource.from_keras_model(model, 'mnist_v2.tflite')\n",
        "print (source.gcs_tflite_uri)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1b6jw_wikQ0",
        "colab_type": "text"
      },
      "source": [
        "Step 3.  Deploy the model to Firebase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK-YsWjPik59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Model Format\n",
        "model_format = ml.TFLiteFormat(model_source=source)\n",
        "\n",
        "# Create a Model object\n",
        "sdk_model_1 = ml.Model(display_name=\"mnist_v2\", model_format=model_format)\n",
        "\n",
        "# Make the Create API call to create the model in Firebase\n",
        "firebase_model_1 = ml.create_model(sdk_model_1)\n",
        "print(firebase_model_1.as_dict())\n",
        "\n",
        "# Publish the model\n",
        "model_id = firebase_model_1.model_id\n",
        "firebase_model_1 = ml.publish_model(model_id)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}